---
phase: 01-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - docker-compose.yml
  - Dockerfile
  - .env.example
  - .env
  - .dockerignore
autonomous: false
requirements: []
user_setup:
  - service: docker-desktop
    why: "Container runtime required for all dev services"
    env_vars: []
    dashboard_config:
      - task: "Install Docker Desktop for Windows"
        location: "https://docs.docker.com/desktop/setup/install/windows-install/"
must_haves:
  truths:
    - "docker compose up starts all 5 services (api, worker, postgres, redis, minio) without errors"
    - "docker compose down && docker compose up brings services back with data intact (PostgreSQL volume, MinIO volume)"
    - "FastAPI API responds at http://localhost:8000/health"
    - "MinIO console is accessible at http://localhost:9001"
    - "PostgreSQL accepts connections on port 5432 with veripost credentials"
  artifacts:
    - path: "docker-compose.yml"
      provides: "Multi-service dev environment definition"
      contains: "pgvector/pgvector:pg16"
    - path: "Dockerfile"
      provides: "Python application container"
      contains: "celery"
    - path: ".env.example"
      provides: "Environment variable template for team"
    - path: ".dockerignore"
      provides: "Build context exclusions"
  key_links:
    - from: "docker-compose.yml"
      to: "Dockerfile"
      via: "api and worker services build from Dockerfile"
      pattern: "build: \\."
    - from: "docker-compose.yml"
      to: ".env"
      via: "env_file directive loads environment"
      pattern: "env_file"
    - from: "api service"
      to: "postgres service"
      via: "depends_on with service_healthy condition"
      pattern: "condition: service_healthy"
---

<objective>
Create the Docker Compose dev environment with all 5 infrastructure services (FastAPI API, Celery worker, PostgreSQL+pgvector, Redis, MinIO) so that the entire stack starts from a single `docker compose up` command and persists data across restarts.

Purpose: Every subsequent plan depends on these services running. Without Docker Compose, there is no PostgreSQL, no Redis, no MinIO, and no Celery worker. This is the absolute foundation.

Output: `docker-compose.yml`, `Dockerfile`, `.env.example`, `.env`, `.dockerignore` — ready for `docker compose up`.
</objective>

<execution_context>
@C:/Users/CameronCarson/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/CameronCarson/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-RESEARCH.md
@docker-compose.yml
@Dockerfile
@pyproject.toml
@app/config.py
</context>

<tasks>

<task type="checkpoint:human-action" gate="blocking">
  <name>Task 1: Verify Docker Desktop + WSL 2 installation</name>
  <action>
Docker Desktop is NOT installed on this machine (confirmed: C:\Program Files\Docker does not exist).

Before Claude can create or test the Docker Compose environment, Docker Desktop must be installed.
  </action>
  <how-to-verify>
1. Open PowerShell as Administrator
2. Run: `wsl --status` — if WSL 2 is not enabled, run: `wsl --install` and restart
3. Download Docker Desktop from https://docs.docker.com/desktop/setup/install/windows-install/
4. Install Docker Desktop (accept defaults, ensure "Use WSL 2 based engine" is checked)
5. Restart if prompted
6. Open Docker Desktop and let it finish initializing
7. Verify in a new terminal: `docker --version` and `docker compose version`
  </how-to-verify>
  <resume-signal>Type "docker ready" when Docker Desktop is installed and `docker compose version` returns output</resume-signal>
</task>

<task type="auto">
  <name>Task 2: Create Docker Compose multi-service environment</name>
  <files>
    docker-compose.yml
    Dockerfile
    .env.example
    .env
    .dockerignore
  </files>
  <action>
Rewrite `docker-compose.yml` to define 5 services with the exact configuration from research:

**Services:**

1. `api` — FastAPI app
   - Build from Dockerfile
   - Port 8000:8000
   - env_file: .env
   - Volume mount: `./app:/app/app` (hot reload)
   - depends_on: postgres (condition: service_healthy), redis (condition: service_started), minio (condition: service_started)
   - command: `sh -c "alembic upgrade head && uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload"`
   - Note: Alembic runs at startup before uvicorn — this ensures migrations are applied automatically

2. `worker` — Celery worker
   - Build from same Dockerfile
   - env_file: .env
   - depends_on: postgres, redis, minio
   - command: `celery -A app.workers.celery_app worker --loglevel=info --pool=solo`
   - Note: `--pool=solo` is used because the worker runs inside a Linux container but we want simplicity for the skeleton. Phase 2+ can switch to prefork if needed.

3. `postgres` — PostgreSQL + pgvector
   - Image: `pgvector/pgvector:pg16`
   - Environment: POSTGRES_USER=veripost, POSTGRES_PASSWORD=veripost, POSTGRES_DB=veripost
   - Port 5432:5432
   - Volume: postgres_data:/var/lib/postgresql/data
   - Healthcheck: `pg_isready -U veripost` with interval 5s, timeout 5s, retries 5

4. `redis` — Redis broker
   - Image: `redis:7-alpine`
   - Port 6379:6379

5. `minio` — MinIO object storage
   - Image: `minio/minio:latest`
   - Command: `server /data --console-address ":9001"`
   - Environment: MINIO_ROOT_USER=veripost, MINIO_ROOT_PASSWORD=veripost123
   - Ports: 9000:9000 (API), 9001:9001 (console)
   - Volume: minio_data:/data

**Named volumes:** postgres_data, minio_data

**Rewrite `Dockerfile`** for both api and worker use:
- Base: python:3.11-slim
- Install system deps for asyncpg: `libpq-dev gcc` (needed to compile asyncpg wheels)
- WORKDIR /app
- Copy pyproject.toml first, install deps (layer caching)
- Copy alembic.ini and alembic/ directory
- Copy app/ directory
- EXPOSE 8000
- Default CMD: uvicorn (overridden by docker-compose command for each service)

**Create `.env.example`** with all environment variables (documented, no secrets):
```
# Application
APP_ENV=development
APP_DEBUG=true
LOG_LEVEL=INFO

# Database
DATABASE_URL=postgresql+asyncpg://veripost:veripost@postgres:5432/veripost

# Redis
REDIS_URL=redis://redis:6379/0

# MinIO
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=veripost
MINIO_SECRET_KEY=veripost123
MINIO_BUCKET=veripost
MINIO_USE_SSL=false

# Celery
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# AI (not needed in Phase 1)
ANTHROPIC_API_KEY=
AI_MODEL=claude-sonnet-4-20250514
```

**Copy `.env.example` to `.env`** (same values for dev — no real secrets in Phase 1).

**Create `.dockerignore`:**
```
.git
.planning
__pycache__
*.pyc
.env
.mypy_cache
.pytest_cache
.ruff_cache
veripost.db
node_modules
*.egg-info
```

**Update `pyproject.toml`** dependencies: add asyncpg>=0.29, pgvector>=0.3, redis>=5.0, celery>=5.0, aiobotocore>=2.0. Remove aiosqlite>=0.20.0.
  </action>
  <verify>
Run `docker compose config` to validate the compose file syntax (does not require services to be running).
Run `docker compose build` to verify the Dockerfile builds successfully.
Run `docker compose up -d` and verify all 5 services are running with `docker compose ps`.
Verify postgres health: `docker compose exec postgres pg_isready -U veripost`
Verify redis: `docker compose exec redis redis-cli ping` (should return PONG)
Verify minio console: open http://localhost:9001 in browser (login: veripost/veripost123)
Verify API: `curl http://localhost:8000/health` (may fail if code changes needed — that is OK, will be fixed in Plan 01-02)
  </verify>
  <done>
All 5 containers start without errors from `docker compose up`. PostgreSQL healthcheck passes. Redis responds to PING. MinIO console is accessible. Named volumes persist data across `docker compose down && docker compose up`.
  </done>
</task>

</tasks>

<verification>
1. `docker compose ps` shows 5 services with status "running" or "Up"
2. `docker compose down && docker compose up -d` — services restart and postgres_data/minio_data volumes survive
3. `.env.example` exists and documents all variables
4. Dockerfile builds without errors
</verification>

<success_criteria>
- Single `docker compose up` command starts the complete dev stack
- PostgreSQL with pgvector extension is accessible on port 5432
- Redis is accessible on port 6379
- MinIO API on port 9000, console on port 9001
- Celery worker container starts (may not process tasks yet — wired in Plan 01-03)
- Data persists across container restarts via named volumes
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-01-SUMMARY.md`
</output>
